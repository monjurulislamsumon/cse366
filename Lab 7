class MultiAgentSearchAgent(Agent):
    """
    This class provides some common elements to all of your
    multi-agent searchers.
    """
    def __init__(self, evalFn='scoreEvaluationFunction', depth='2'):
        self.index = 0  # Pacman is always agent index 0
        self.evaluationFunction = util.lookup(evalFn, globals())
        self.depth = int(depth)

# Definition of AlphaBetaAgent class
class AlphaBetaAgent(MultiAgentSearchAgent):
    """
    Your minimax agent with alpha-beta pruning.
    """
    def getAction(self, gameState):
        """
        Returns the minimax action using self.depth and self.evaluationFunction
        with alpha-beta pruning.
        """
        alpha = float('-inf')
        beta = float('inf')
        action, _ = self.alphabeta(gameState, 0, 0, alpha, beta)
        return action

    def alphabeta(self, gameState, depth, agentIndex, alpha, beta):
        # Alpha-beta pruning implementation goes here
        pass
class AlphaBetaAgent(MultiAgentSearchAgent):
    """
    Your minimax agent with alpha-beta pruning.
    """
    def getAction(self, gameState):
        """
        Returns the minimax action using self.depth and self.evaluationFunction
        with alpha-beta pruning.
        """
        alpha = float('-inf')
        beta = float('inf')
        action, _ = self.alphabeta(gameState, 0, 0, alpha, beta)
        return action

    def alphabeta(self, gameState, depth, agentIndex, alpha, beta):
        # Check if we have reached a terminal state or the maximum depth
        if depth == self.depth or gameState.isWin() or gameState.isLose():
            return None, self.evaluationFunction(gameState)
        
        # Roll over agent index to 0 (Pacman) if all agents have played their turn
        if agentIndex >= gameState.getNumAgents():
            agentIndex = 0
            depth += 1  # Increase depth when all agents have played

        # If Pacman's turn (Maximizer)
        if agentIndex == 0:
            return self.maxValue(gameState, depth, agentIndex, alpha, beta)
        # If it's one of the ghost's turn (Minimizer)
        else:
            return self.minValue(gameState, depth, agentIndex, alpha, beta)

    def maxValue(self, gameState, depth, agentIndex, alpha, beta):
        # Maximizer for Pacman
        maxEval = float('-inf')
        bestAction = None

        for action in gameState.getLegalActions(agentIndex):
            successor = gameState.generateSuccessor(agentIndex, action)
            _, evaluation = self.alphabeta(successor, depth, agentIndex + 1, alpha, beta)
            
            if evaluation > maxEval:
                maxEval = evaluation
                bestAction = action
            
            alpha = max(alpha, maxEval)
            
            # Pruning
            if beta <= alpha:
                break
        
        return bestAction, maxEval

    def minValue(self, gameState, depth, agentIndex, alpha, beta):
        # Minimizer for Ghosts
        minEval = float('inf')
        bestAction = None

        for action in gameState.getLegalActions(agentIndex):
            successor = gameState.generateSuccessor(agentIndex, action)
            _, evaluation = self.alphabeta(successor, depth, agentIndex + 1, alpha, beta)
            
            if evaluation < minEval:
                minEval = evaluation
                bestAction = action

            beta = min(beta, minEval)
            
            # Pruning
            if beta <= alpha:
                break
        
        return bestAction, minEval
Lab-6.py
Displaying Lab-6.py.
github.com
Raifa
Raifa Runa
# -*- coding: utf-8 -*-
"""lab final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1umx_xq6-xL0B5j4i6FBznl-_U1cammjc
"""



from google.colab import drive
drive.mount('/content/drive')

pip install grad-cam==1.4.8

# Import necessary libraries
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, random_split
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image
from torchvision.models import resnet50, ResNet50_Weights

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Dataset Preprocessing
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(30),
    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Load Dataset
dataset_path = "/content/drive/MyDrive/366/caltech-101"
dataset = datasets.ImageFolder(root=dataset_path, transform=transform)
print("Classes:", dataset.classes)

# Split Dataset
train_size = int(0.8 * len(dataset))
val_size = int(0.1 * len(dataset))
test_size = len(dataset) - train_size - val_size
train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])

train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
val_loader = DataLoader(val_data, batch_size=32)
test_loader = DataLoader(test_data, batch_size=32)

# Define Model
model = resnet50(weights=ResNet50_Weights.DEFAULT)
model.fc = nn.Linear(model.fc.in_features, len(dataset.classes))  # Match class count
model = model.to(device)

# Define Loss and Optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training Loop
epochs = 10
for epoch in range(epochs):
    model.train()
    total_loss = 0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        # Forward and backward
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    print(f"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}")

# Validation
model.eval()
correct = 0
with torch.no_grad():
    for images, labels in val_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, preds = torch.max(outputs, 1)
        correct += (preds == labels).sum().item()

print(f"Validation Accuracy: {correct / len(val_data) * 100:.2f}%")


# Step 6: Test Evaluation
y_true, y_pred = [], []
model.eval()
with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, preds = torch.max(outputs, 1)
        y_true.extend(labels.cpu().numpy())
        y_pred.extend(preds.cpu().numpy())

# Confusion Matrix and Classification Report
cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:\n", cm)
print("Classification Report:\n", classification_report(y_true, y_pred))

# Step 7: Grad-CAM Visualization
target_layer = model.layer4[-1]  # Adjust for ResNet50
cam = GradCAM(model=model, target_layer=target_layer, use_cuda=torch.cuda.is_available())

for images, labels in test_loader:
    images = images.to(device)
    grayscale_cam = cam(input_tensor=images, target_category=None)
    for i in range(len(images)):
        image_np = images[i].cpu().permute(1, 2, 0).numpy()
        cam_image = show_cam_on_image(image_np, grayscale_cam[i])
        plt.imshow(cam_image)
        plt.show()
    break  # Display Grad-CAM for one batch
colab.research.google.com
